{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Import the libraries","metadata":{}},{"cell_type":"code","source":"import json\nimport pandas as pd\nimport numpy as np\nfrom nltk.tokenize import WordPunctTokenizer\nimport os\nimport urllib.request\nimport tensorflow as tf\nimport torch\nimport os\nimport torchvision\nimport tarfile\nfrom torch.utils.data import random_split\nfrom torchvision.datasets.utils import download_url\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport spacy\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:04:53.424264Z","iopub.execute_input":"2022-01-05T09:04:53.42466Z","iopub.status.idle":"2022-01-05T09:04:53.432436Z","shell.execute_reply.started":"2022-01-05T09:04:53.424628Z","shell.execute_reply":"2022-01-05T09:04:53.430701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset\nimport torch.nn as nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:03:02.662335Z","iopub.execute_input":"2022-01-05T09:03:02.662697Z","iopub.status.idle":"2022-01-05T09:03:02.668002Z","shell.execute_reply.started":"2022-01-05T09:03:02.662656Z","shell.execute_reply":"2022-01-05T09:03:02.666829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install openpyxl","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:03:02.669948Z","iopub.execute_input":"2022-01-05T09:03:02.670915Z","iopub.status.idle":"2022-01-05T09:03:14.932671Z","shell.execute_reply.started":"2022-01-05T09:03:02.670868Z","shell.execute_reply":"2022-01-05T09:03:14.931673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_excel('../input/enterpret-absa/train.xlsx')\ntest=pd.read_excel('../input/enterpret-absa/test.xlsx')\n","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:03:14.93906Z","iopub.execute_input":"2022-01-05T09:03:14.941598Z","iopub.status.idle":"2022-01-05T09:03:16.257383Z","shell.execute_reply.started":"2022-01-05T09:03:14.94155Z","shell.execute_reply":"2022-01-05T09:03:16.256412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['label'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:03:16.259085Z","iopub.execute_input":"2022-01-05T09:03:16.259461Z","iopub.status.idle":"2022-01-05T09:03:16.279556Z","shell.execute_reply.started":"2022-01-05T09:03:16.259393Z","shell.execute_reply":"2022-01-05T09:03:16.278304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_data(data):\n    for i in range(len(data)):\n        if(type(data.loc[i,'aspect'])==float):\n            data.loc[i,'aspect']=str(data.loc[i,'aspect'])\n    data['text_tok'] = data['text'].apply(lambda x: x.lower())\n    data['text_tok'] = data['text_tok'].apply(custom_tokenize)\n    data['aspect_tok'] = data['aspect'].apply(lambda x: x.lower())\n    data['aspect_tok'] = data['aspect_tok'].apply(custom_tokenize)\n    return data\n\ndef custom_tokenize(text):#split sentences into a list of word\n    tokenizer = WordPunctTokenizer()\n    tokens = tokenizer.tokenize(text)\n    words = [word for word in tokens if word.isalnum()]\n    return words\n\ndef max_len(data):#function to find maximum length of text and aspect\n    max_text=0\n    max_asp=0\n    for i in range(len(data)):\n        max_text=max(max_text,len(data.loc[i,'text_tok']))\n        max_asp=max(max_asp,len(data.loc[i,'aspect_tok']))\n    return max_text,max_asp\n\ndef find_w(data_train_1,data_test_1):#function to create word to indices dictionary\n    word2idx={}\n    word2idx={}\n    i=0\n    for sentence in data_train_1['text_tok']:\n        for word in sentence:\n            if word not in word2idx.values():\n                word2idx[i]= word\n                i=i+1\n                \n    for sentence in data_train_1['aspect_tok']:\n        for word in sentence:\n            if word not in word2idx.values():\n                word2idx[i]= word\n                i=i+1\n     \n    for sentence in data_test_1['text_tok']:\n        for word in sentence:\n            if word not in word2idx.values():\n                word2idx[i]= word\n                i=i+1\n                \n    for sentence in data_test_1['aspect_tok']:\n        for word in sentence:\n            if word not in word2idx.values():\n                word2idx[i]= word\n                i=i+1\n                \n    return word2idx\n    \n\n\ndef create_vocab(data_train_1,data_test_1):\n    word2idx = {}\n    \n    for sentence in data_train_1['text_tok']:\n        for word in sentence:\n            if word not in word2idx:\n                word2idx[word] = len(word2idx)\n                \n    for sentence in data_train_1['aspect_tok']:\n        for word in sentence:\n            if word not in word2idx:\n                word2idx[word] = len(word2idx)\n                \n    for sentence in data_test_1['text_tok']:\n        for word in sentence:\n            if word not in word2idx:\n                word2idx[word] = len(word2idx)\n                \n    for sentence in data_test_1['aspect_tok']:\n        for word in sentence:\n            if word not in word2idx:\n                word2idx[word] = len(word2idx)\n    \n    idx2word ={v: k for k, v in word2idx.items()}\n    return word2idx,idx2word\n\n\ndef create_dict(vocab,embed):#function to create word to indices dictionary\n    word2idx={}\n    max_len=len(vocab)\n    w_ind={}\n    i_w={}\n    print(max_len)\n    for i in range(len(vocab)):\n        if vocab[i] not in w_ind:\n            w_ind[vocab[i]]=len(w_ind)+1\n            i_w[i+1]=vocab[i]\n    \n    return   w_ind,i_w    \n","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:03:16.29434Z","iopub.execute_input":"2022-01-05T09:03:16.295085Z","iopub.status.idle":"2022-01-05T09:03:16.319728Z","shell.execute_reply.started":"2022-01-05T09:03:16.295004Z","shell.execute_reply":"2022-01-05T09:03:16.318736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_2=train.copy()\ndata=parse_data(train_2)\n\ntest_2=test.copy()\ndata_test=parse_data(test_2)\n#print(data)\nmax_tex,max_asp=max_len(data)\nvocab=find_w(data,data_test)\nw_ind,i_w=create_dict(vocab,300)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:03:16.321284Z","iopub.execute_input":"2022-01-05T09:03:16.322201Z","iopub.status.idle":"2022-01-05T09:03:17.78012Z","shell.execute_reply.started":"2022-01-05T09:03:16.322156Z","shell.execute_reply":"2022-01-05T09:03:17.778286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#vocab","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:03:17.781813Z","iopub.execute_input":"2022-01-05T09:03:17.782084Z","iopub.status.idle":"2022-01-05T09:03:17.787793Z","shell.execute_reply.started":"2022-01-05T09:03:17.782046Z","shell.execute_reply":"2022-01-05T09:03:17.786582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#save vocabulary in a json file for future use\na_file = open(\"full_vocabulary.json\", \"w\")\njson.dump(vocab, a_file)\na_file.close()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:17:24.372874Z","iopub.execute_input":"2022-01-05T09:17:24.373183Z","iopub.status.idle":"2022-01-05T09:17:24.40586Z","shell.execute_reply.started":"2022-01-05T09:17:24.373151Z","shell.execute_reply":"2022-01-05T09:17:24.404533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:05:09.754993Z","iopub.execute_input":"2022-01-05T09:05:09.755287Z","iopub.status.idle":"2022-01-05T09:05:09.777022Z","shell.execute_reply.started":"2022-01-05T09:05:09.755256Z","shell.execute_reply":"2022-01-05T09:05:09.776047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:06:14.875066Z","iopub.execute_input":"2022-01-05T09:06:14.875422Z","iopub.status.idle":"2022-01-05T09:06:14.881081Z","shell.execute_reply.started":"2022-01-05T09:06:14.875383Z","shell.execute_reply":"2022-01-05T09:06:14.879788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"glove = pd.read_csv('../input/glove-data/glove.6B.300d.txt', sep=\" \", quoting=3, header=None, index_col=0)\nglove_embedding = {key: val.values for key, val in glove.T.items()}","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:54:35.974485Z","iopub.execute_input":"2022-01-05T08:54:35.974748Z","iopub.status.idle":"2022-01-05T08:55:17.642607Z","shell.execute_reply.started":"2022-01-05T08:54:35.974718Z","shell.execute_reply":"2022-01-05T08:55:17.641841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emb_mat=np.zeros((len(vocab)+1,300))  #matrix of glove embeddings of all words in test and train sets","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:17.644506Z","iopub.execute_input":"2022-01-05T08:55:17.644757Z","iopub.status.idle":"2022-01-05T08:55:17.650524Z","shell.execute_reply.started":"2022-01-05T08:55:17.644721Z","shell.execute_reply":"2022-01-05T08:55:17.649744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#emb_mat.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:42:04.088904Z","iopub.execute_input":"2022-01-02T15:42:04.089323Z","iopub.status.idle":"2022-01-02T15:42:04.100734Z","shell.execute_reply.started":"2022-01-02T15:42:04.089284Z","shell.execute_reply":"2022-01-02T15:42:04.100016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(len(i_w)):\n    i_word = i_w[i+1]\n    if(i_word not in glove_embedding.keys()):\n        emb_mat[i+1]=np.random.rand(300)\n    else:\n        emb_mat[i+1]=glove_embedding[i_word]\n    #vocab.append(i_word)\n    #embeddings.append(i_embeddings)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:17.652385Z","iopub.execute_input":"2022-01-05T08:55:17.653023Z","iopub.status.idle":"2022-01-05T08:55:17.688293Z","shell.execute_reply.started":"2022-01-05T08:55:17.652986Z","shell.execute_reply":"2022-01-05T08:55:17.687568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#emb_mat[1]","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:42:04.137311Z","iopub.execute_input":"2022-01-02T15:42:04.137634Z","iopub.status.idle":"2022-01-02T15:42:04.148894Z","shell.execute_reply.started":"2022-01-02T15:42:04.137595Z","shell.execute_reply":"2022-01-02T15:42:04.147891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:17:55.421134Z","iopub.execute_input":"2022-01-02T15:17:55.421499Z","iopub.status.idle":"2022-01-02T15:17:55.461255Z","shell.execute_reply.started":"2022-01-02T15:17:55.421459Z","shell.execute_reply":"2022-01-02T15:17:55.460549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tex=np.empty([4000,278])\naspec=np.empty([4000,8])\nfor i in range(len(data))::#create a index encoding of all sentences in train set\n    sent=data.loc[i,'text_tok']\n    asp=data.loc[i,'aspect_tok']\n    encoded_sentences = np.array([w_ind[word] for word in sent])\n    encoded_sen=np.append(encoded_sentences,np.zeros(278-len(encoded_sentences)))\n    encoded_asp=np.array([w_ind[word] for word in asp])\n    encoded_as=np.append(encoded_asp,np.zeros(8-len(encoded_asp)))\n    tex[i]=encoded_sen\n    aspec[i]=encoded_as\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:17.690121Z","iopub.execute_input":"2022-01-05T08:55:17.690314Z","iopub.status.idle":"2022-01-05T08:55:17.905414Z","shell.execute_reply.started":"2022-01-05T08:55:17.69029Z","shell.execute_reply":"2022-01-05T08:55:17.904436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tex=torch.LongTensor(tex)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:17.906823Z","iopub.execute_input":"2022-01-05T08:55:17.907107Z","iopub.status.idle":"2022-01-05T08:55:17.925967Z","shell.execute_reply.started":"2022-01-05T08:55:17.907067Z","shell.execute_reply":"2022-01-05T08:55:17.92518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aspec=torch.LongTensor(aspec)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:17.927385Z","iopub.execute_input":"2022-01-05T08:55:17.927664Z","iopub.status.idle":"2022-01-05T08:55:17.933715Z","shell.execute_reply.started":"2022-01-05T08:55:17.927625Z","shell.execute_reply":"2022-01-05T08:55:17.932586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['label']=data['label'].apply(lambda x:int(x))","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:17.935176Z","iopub.execute_input":"2022-01-05T08:55:17.936003Z","iopub.status.idle":"2022-01-05T08:55:17.948486Z","shell.execute_reply.started":"2022-01-05T08:55:17.935963Z","shell.execute_reply":"2022-01-05T08:55:17.947669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels= torch.tensor(train['label'].values)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:17.950178Z","iopub.execute_input":"2022-01-05T08:55:17.950457Z","iopub.status.idle":"2022-01-05T08:55:17.958642Z","shell.execute_reply.started":"2022-01-05T08:55:17.950421Z","shell.execute_reply":"2022-01-05T08:55:17.957786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#tex.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:42:04.426459Z","iopub.execute_input":"2022-01-02T15:42:04.427Z","iopub.status.idle":"2022-01-02T15:42:04.433255Z","shell.execute_reply.started":"2022-01-02T15:42:04.426966Z","shell.execute_reply":"2022-01-02T15:42:04.432526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating train and validation sets.Since data is almost at random ,we can directly do splitting without using any sampler.","metadata":{}},{"cell_type":"code","source":"train_tex=tex[:3200]\ntrain_aspec=aspec[:3200]\ntrain_labels=labels[:3200]","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:17.960015Z","iopub.execute_input":"2022-01-05T08:55:17.960541Z","iopub.status.idle":"2022-01-05T08:55:17.969125Z","shell.execute_reply.started":"2022-01-05T08:55:17.960488Z","shell.execute_reply":"2022-01-05T08:55:17.968341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_tex=tex[3200:]\nval_aspec=aspec[3200:]\nval_labels=labels[3200:]","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:17.972276Z","iopub.execute_input":"2022-01-05T08:55:17.97312Z","iopub.status.idle":"2022-01-05T08:55:17.979409Z","shell.execute_reply.started":"2022-01-05T08:55:17.973079Z","shell.execute_reply":"2022-01-05T08:55:17.978659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds=TensorDataset(train_tex,train_aspec,train_labels)\nbatch_size = 2\ntrain_dl = DataLoader(train_ds, batch_size, shuffle=False)#creating dataloaders","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:17.980804Z","iopub.execute_input":"2022-01-05T08:55:17.981407Z","iopub.status.idle":"2022-01-05T08:55:17.98972Z","shell.execute_reply.started":"2022-01-05T08:55:17.981366Z","shell.execute_reply":"2022-01-05T08:55:17.98896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_ds=TensorDataset(val_tex,val_aspec,val_labels)\nbatch_size = 2\nval_dl = DataLoader(val_ds, batch_size, shuffle=False)#creating dataloaders","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:17.991121Z","iopub.execute_input":"2022-01-05T08:55:17.991662Z","iopub.status.idle":"2022-01-05T08:55:18.000814Z","shell.execute_reply.started":"2022-01-05T08:55:17.991624Z","shell.execute_reply":"2022-01-05T08:55:17.999866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for a,b,c in train_dl:\n #   print(a)\n  #  print(b)\n   # print(c)\n    #c2=c.to(torch.long)\n    #print(type(c))\n    #print(c2)\n    #break","metadata":{"execution":{"iopub.status.busy":"2022-01-02T15:55:34.857243Z","iopub.execute_input":"2022-01-02T15:55:34.857498Z","iopub.status.idle":"2022-01-02T15:55:34.879298Z","shell.execute_reply.started":"2022-01-02T15:55:34.857464Z","shell.execute_reply":"2022-01-02T15:55:34.878571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:18.004024Z","iopub.execute_input":"2022-01-05T08:55:18.004265Z","iopub.status.idle":"2022-01-05T08:55:18.016077Z","shell.execute_reply.started":"2022-01-05T08:55:18.004216Z","shell.execute_reply":"2022-01-05T08:55:18.01471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device=get_default_device()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:18.01766Z","iopub.execute_input":"2022-01-05T08:55:18.018227Z","iopub.status.idle":"2022-01-05T08:55:18.02836Z","shell.execute_reply.started":"2022-01-05T08:55:18.018184Z","shell.execute_reply":"2022-01-05T08:55:18.027564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class aspectClassificationBase(nn.Module):#utility class for training and testing.Needs to be present\n                          #in all notebooks since it is inherited by models.\n\n\n    def training_step(self,batch):\n        text,aspect,labels=batch\n        out=self(text,aspect)\n        #labels=int(labels)\n        labels=labels.to(torch.long)\n        loss=F.cross_entropy(out,labels)\n        return loss\n    \n    def validation_step(self,batch):\n        text,aspect,labels=batch\n        out=self(text,aspect)\n        labels=labels.to(torch.long)\n        loss=F.cross_entropy(out,labels)\n        acc=accuracy(labels,out)\n        return {'val_loss':loss.detach(),'val_acc':acc}\n    \n    def validation_epoch_end(self,result):\n        loss=[x['val_loss'] for x in result]\n        acc= [x['val_acc'] for x in result]\n        l_b=torch.stack(loss).mean()\n        a_b=torch.stack(acc).mean()\n        return {'val_loss':l_b.item(), 'val_acc': a_b.item()}\n    \n    def epoch_end(self,epoch,result):\n        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch,result['val_loss'], result['val_acc']))","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:18.029864Z","iopub.execute_input":"2022-01-05T08:55:18.030407Z","iopub.status.idle":"2022-01-05T08:55:18.041233Z","shell.execute_reply.started":"2022-01-05T08:55:18.030356Z","shell.execute_reply":"2022-01-05T08:55:18.040364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LSTM_imp(aspectClassificationBase):\n    def __init__(self,emb_mat,num_classes,embedding_dim,vocab_size_t,vocab_size_a):\n        super(LSTM_imp,self).__init__()\n        self.embedding_dim = embedding_dim\n        self.vocab_size_t = vocab_size_t\n        self.vocab_size_a=vocab_size_a\n        self.polarities=num_classes\n        self.embed = nn.Embedding.from_pretrained(emb_mat,freeze=True)\n        self.lstm =nn.LSTM(self.embedding_dim,128,batch_first=True,num_layers=2,dropout=0.2,bidirectional=True)\n        #self.lstm_a  =nn.LSTM(self.embedding_dim,128,batch_first=True,bidirectional=True)\n        self.dense = nn.Linear(self.vocab_size_t*self.vocab_size_a,self.polarities)\n        #self.softmax=nn.Softmax(dim=1)\n\n    def forward(self, text,aspect):\n        #asp_raw_indices=inputs[:,278:,:]\n       # y1=inputs[0][278:][:]\n        #y2=inputs[1][278:][:]\n        \n        #text_raw_indices = torch.stack([x1,x2])\n        #asp_raw_indices=torch.stack([y1,y2])\n        #print(asp_raw_indices.shape)\n        #print(text_raw_indices.shape)\n        x= self.embed(text)\n        x,_=self.lstm(x)\n        #print(x.shape)\n        \n        x2=self.embed(aspect)\n        x2,_=self.lstm(x2)\n        #print(x2.shape)\n        x2=x2.permute(0,2,1)\n        \n        x3=torch.matmul(x,x2)\n        #print(x3.shape)\n        x3=x3.reshape(batch_size,-1)\n        x3=self.dense(x3)\n        #print(x3.shape)\n       \n        #x_len = torch.sum(text_raw_indices != 0, dim=-1)\n        #_, (h_n, _) = self.lstm(x, x_len)\n        #out = self.dense(h_n[0])\n        return x3","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:42.885933Z","iopub.execute_input":"2022-01-05T08:55:42.886599Z","iopub.status.idle":"2022-01-05T08:55:42.895289Z","shell.execute_reply.started":"2022-01-05T08:55:42.886561Z","shell.execute_reply":"2022-01-05T08:55:42.894585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"emb_mat_t=torch.tensor(emb_mat)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:44.614425Z","iopub.execute_input":"2022-01-05T08:55:44.615126Z","iopub.status.idle":"2022-01-05T08:55:44.62189Z","shell.execute_reply.started":"2022-01-05T08:55:44.615075Z","shell.execute_reply":"2022-01-05T08:55:44.62111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab_size_t=max_tex\nvocab_size_a=max_asp\n","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:45.111781Z","iopub.execute_input":"2022-01-05T08:55:45.112468Z","iopub.status.idle":"2022-01-05T08:55:45.115834Z","shell.execute_reply.started":"2022-01-05T08:55:45.112429Z","shell.execute_reply":"2022-01-05T08:55:45.115162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dim=300\nnumber_classes=3","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:51.906825Z","iopub.execute_input":"2022-01-05T08:55:51.90717Z","iopub.status.idle":"2022-01-05T08:55:51.911527Z","shell.execute_reply.started":"2022-01-05T08:55:51.907132Z","shell.execute_reply":"2022-01-05T08:55:51.910794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model =LSTM_imp(emb_mat_t,number_classes,embedding_dim,vocab_size_t,vocab_size_a)#creating instance of model class\nmodel.double()\nmodel\n","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:55.148016Z","iopub.execute_input":"2022-01-05T08:55:55.148488Z","iopub.status.idle":"2022-01-05T08:55:55.165363Z","shell.execute_reply.started":"2022-01-05T08:55:55.148453Z","shell.execute_reply":"2022-01-05T08:55:55.164649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dl=DeviceDataLoader(train_dl,device)\nval_dl=DeviceDataLoader(val_dl,device)#transporting dataloaders to device","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:57.77837Z","iopub.execute_input":"2022-01-05T08:55:57.779233Z","iopub.status.idle":"2022-01-05T08:55:57.783582Z","shell.execute_reply.started":"2022-01-05T08:55:57.779182Z","shell.execute_reply":"2022-01-05T08:55:57.782879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"to_device(model, device)#transporting models to device","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:55:59.168755Z","iopub.execute_input":"2022-01-05T08:55:59.169272Z","iopub.status.idle":"2022-01-05T08:56:07.174559Z","shell.execute_reply.started":"2022-01-05T08:55:59.169232Z","shell.execute_reply":"2022-01-05T08:56:07.173838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def accuracy(act,pred):\n    _, preds = torch.max(pred, dim=1)\n    #print(preds[0])\n    #print(act[0])\n    return torch.tensor(torch.sum(preds==act).item() / len(preds))","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:56:07.176082Z","iopub.execute_input":"2022-01-05T08:56:07.176434Z","iopub.status.idle":"2022-01-05T08:56:07.181076Z","shell.execute_reply.started":"2022-01-05T08:56:07.176381Z","shell.execute_reply":"2022-01-05T08:56:07.180162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    optimizer = opt_func(model.parameters(), lr)\n    history = [] # for recording epoch-wise results\n    \n    for epoch in range(epochs):\n        \n        # Training Phase \n        for batch in train_loader:\n            loss = model.training_step(batch)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        \n        # Validation phase\n        result = evaluate(model, val_loader)\n        model.epoch_end(epoch, result)\n        history.append(result)\n\n    return history","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:56:07.182379Z","iopub.execute_input":"2022-01-05T08:56:07.182811Z","iopub.status.idle":"2022-01-05T08:56:07.195755Z","shell.execute_reply.started":"2022-01-05T08:56:07.182774Z","shell.execute_reply":"2022-01-05T08:56:07.194954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, val_loader):\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:56:07.198612Z","iopub.execute_input":"2022-01-05T08:56:07.1988Z","iopub.status.idle":"2022-01-05T08:56:07.205607Z","shell.execute_reply.started":"2022-01-05T08:56:07.198775Z","shell.execute_reply":"2022-01-05T08:56:07.204857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit(10, 0.01, model, train_dl, val_dl)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T08:56:07.20671Z","iopub.execute_input":"2022-01-05T08:56:07.207422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit(10,0.005,model,train_dl,val_dl)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, 'lstm_bi_e30.pth')","metadata":{},"execution_count":null,"outputs":[]}]}