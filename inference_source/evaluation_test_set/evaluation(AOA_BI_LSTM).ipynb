{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This inference file may give errors if words not included in either the train or test set are given.","metadata":{}},{"cell_type":"code","source":"import pandas as pd #Import the libraries\nimport numpy as np\nfrom nltk.tokenize import WordPunctTokenizer\nimport os\nimport urllib.request\nimport tensorflow as tf\nimport torch\nimport os\nimport torchvision\nimport tarfile\nfrom torch.utils.data import random_split\nfrom torchvision.datasets.utils import download_url\nimport matplotlib.pyplot as plt\nimport torch.nn as nn\nimport spacy\nfrom torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:58:39.886669Z","iopub.execute_input":"2022-01-05T16:58:39.887289Z","iopub.status.idle":"2022-01-05T16:58:52.71296Z","shell.execute_reply.started":"2022-01-05T16:58:39.887167Z","shell.execute_reply":"2022-01-05T16:58:52.711696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom transformers import BertModel\n\nfrom transformers.models.bert.modeling_bert import BertPooler, BertSelfAttention\nfrom transformers import BertTokenizer\nfrom torch.utils.data import Dataset\n#pretrained_bert=\"bert-base-uncased\"\nimport json","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:58:52.716176Z","iopub.execute_input":"2022-01-05T16:58:52.716798Z","iopub.status.idle":"2022-01-05T16:58:54.463421Z","shell.execute_reply.started":"2022-01-05T16:58:52.716749Z","shell.execute_reply":"2022-01-05T16:58:54.462224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install openpyxl","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:58:54.464946Z","iopub.execute_input":"2022-01-05T16:58:54.465282Z","iopub.status.idle":"2022-01-05T16:59:06.373432Z","shell.execute_reply.started":"2022-01-05T16:58:54.465238Z","shell.execute_reply":"2022-01-05T16:59:06.372221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test=pd.read_excel('../input/enterpret-absa/test.xlsx')","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:06.376737Z","iopub.execute_input":"2022-01-05T16:59:06.377229Z","iopub.status.idle":"2022-01-05T16:59:07.020034Z","shell.execute_reply.started":"2022-01-05T16:59:06.377145Z","shell.execute_reply":"2022-01-05T16:59:07.018942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_data(data):\n    for i in range(len(data)):\n        if(type(data.loc[i,'aspect'])==float):\n            data.loc[i,'aspect']=str(data.loc[i,'aspect'])\n    data['text_tok'] = data['text'].apply(lambda x: x.lower())\n    data['text_tok'] = data['text_tok'].apply(custom_tokenize)\n    data['aspect_tok'] = data['aspect'].apply(lambda x: x.lower())\n    data['aspect_tok'] = data['aspect_tok'].apply(custom_tokenize)\n    return data\n\ndef custom_tokenize(text):\n    tokenizer = WordPunctTokenizer()\n    tokens = tokenizer.tokenize(text)\n    words = [word for word in tokens if word.isalnum()]\n    return words\n\ndef max_len(data):\n    max_text=0\n    max_asp=0\n    for i in range(len(data)):\n        max_text=max(max_text,len(data.loc[i,'text_tok']))\n        max_asp=max(max_asp,len(data.loc[i,'aspect_tok']))\n    return max_text,max_asp\n\ndef find_w(data_train_1):\n    word2idx={}\n    i=0\n    for sentence in data_train_1['text_tok']:\n        for word in sentence:\n            if word not in word2idx.values():\n                word2idx[i]= word\n                i=i+1\n    for sentence in data_train_1['aspect_tok']:\n        for word in sentence:\n            if word not in word2idx.values():\n                word2idx[i]= word\n                i=i+1\n                \n    return word2idx\n    \n\n\ndef create_vocab(data_train_1):\n    word2idx = {}\n    \n    for sentence in data_train_1['text_tok']:\n        for word in sentence:\n            if word not in word2idx:\n                word2idx[word] = len(word2idx)\n    for sentence in data_train_1['aspect_tok']:\n        for word in sentence:\n            if word not in word2idx:\n                word2idx[word] = len(word2idx)\n    idx2word ={v: k for k, v in word2idx.items()}\n    return word2idx,idx2word\n\ndef create_dict(vocab,embed):\n    max_len=len(vocab)\n    w_ind={}\n    i_w={}\n    print(max_len)\n    for i in range(len(vocab)):\n        if vocab[str(i)] not in w_ind:\n            w_ind[vocab[str(i)]]=len(w_ind)+1\n            i_w[i+1]=vocab[str(i)]\n    \n    return   w_ind,i_w    \n","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:07.021456Z","iopub.execute_input":"2022-01-05T16:59:07.02175Z","iopub.status.idle":"2022-01-05T16:59:07.041521Z","shell.execute_reply.started":"2022-01-05T16:59:07.021705Z","shell.execute_reply":"2022-01-05T16:59:07.040132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test2=test.copy()\ndata=parse_data(test2)\n\n#print(data)\nmax_tex,max_asp=max_len(data)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:07.043108Z","iopub.execute_input":"2022-01-05T16:59:07.043443Z","iopub.status.idle":"2022-01-05T16:59:07.137851Z","shell.execute_reply.started":"2022-01-05T16:59:07.043396Z","shell.execute_reply":"2022-01-05T16:59:07.136878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:07.139542Z","iopub.execute_input":"2022-01-05T16:59:07.139854Z","iopub.status.idle":"2022-01-05T16:59:07.174039Z","shell.execute_reply.started":"2022-01-05T16:59:07.139811Z","shell.execute_reply":"2022-01-05T16:59:07.172699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Loading the vocab file which stored words to index dictionary","metadata":{}},{"cell_type":"code","source":"vocab_file= open(\"../input/lstm-vocab/full_vocabulary.json\")\nvocab_f=vocab_file.read()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:07.176093Z","iopub.execute_input":"2022-01-05T16:59:07.176446Z","iopub.status.idle":"2022-01-05T16:59:07.192334Z","shell.execute_reply.started":"2022-01-05T16:59:07.176401Z","shell.execute_reply":"2022-01-05T16:59:07.191416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nvocab=json.loads(vocab_f)\nprint(len(vocab))\n#w_ind,i_w=create_dict(vocab,300)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:07.194075Z","iopub.execute_input":"2022-01-05T16:59:07.194395Z","iopub.status.idle":"2022-01-05T16:59:07.202945Z","shell.execute_reply.started":"2022-01-05T16:59:07.194353Z","shell.execute_reply":"2022-01-05T16:59:07.201718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"w_ind,i_w=create_dict(vocab,300)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:07.208066Z","iopub.execute_input":"2022-01-05T16:59:07.208767Z","iopub.status.idle":"2022-01-05T16:59:07.22611Z","shell.execute_reply.started":"2022-01-05T16:59:07.208723Z","shell.execute_reply":"2022-01-05T16:59:07.225041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#i_w","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:07.22776Z","iopub.execute_input":"2022-01-05T16:59:07.228103Z","iopub.status.idle":"2022-01-05T16:59:07.232756Z","shell.execute_reply.started":"2022-01-05T16:59:07.228059Z","shell.execute_reply":"2022-01-05T16:59:07.231561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#vocab.keys()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:07.234628Z","iopub.execute_input":"2022-01-05T16:59:07.235205Z","iopub.status.idle":"2022-01-05T16:59:07.243595Z","shell.execute_reply.started":"2022-01-05T16:59:07.235158Z","shell.execute_reply":"2022-01-05T16:59:07.24214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_tex=278#max sentence length\nmax_asp=8#max aspect length","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:07.245288Z","iopub.execute_input":"2022-01-05T16:59:07.245644Z","iopub.status.idle":"2022-01-05T16:59:07.253534Z","shell.execute_reply.started":"2022-01-05T16:59:07.245598Z","shell.execute_reply":"2022-01-05T16:59:07.251899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tex=np.empty([len(data),max_tex])\naspec=np.empty([len(data),max_asp])\nfor i in range(len(data)):#creating a matrix of glove embeddings of all words in test\n    #print(i)\n    sent=data.loc[i,'text_tok']\n    asp=data.loc[i,'aspect_tok']\n    encoded_sentences = np.array([w_ind[word] for word in sent])\n    if len(encoded_sentences)>278:\n        encoded_sentences=encoded_sentences[:278]\n    encoded_sen=np.append(encoded_sentences,np.zeros(max_tex-len(encoded_sentences)))\n    encoded_asp=np.array([w_ind[word] for word in asp])\n    encoded_as=np.append(encoded_asp,np.zeros(max_asp-len(encoded_asp)))\n    tex[i]=encoded_sen\n    aspec[i]=encoded_as","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:07.255643Z","iopub.execute_input":"2022-01-05T16:59:07.25606Z","iopub.status.idle":"2022-01-05T16:59:07.349317Z","shell.execute_reply.started":"2022-01-05T16:59:07.25601Z","shell.execute_reply":"2022-01-05T16:59:07.348161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data.loc[284]","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:07.351232Z","iopub.execute_input":"2022-01-05T16:59:07.351614Z","iopub.status.idle":"2022-01-05T16:59:07.35762Z","shell.execute_reply.started":"2022-01-05T16:59:07.351569Z","shell.execute_reply":"2022-01-05T16:59:07.35617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tex=torch.LongTensor(tex)\naspec=torch.LongTensor(aspec)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:07.360967Z","iopub.execute_input":"2022-01-05T16:59:07.361333Z","iopub.status.idle":"2022-01-05T16:59:07.384591Z","shell.execute_reply.started":"2022-01-05T16:59:07.361288Z","shell.execute_reply":"2022-01-05T16:59:07.383469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ds=TensorDataset(tex,aspec)\nbatch_size = 20 #put batch size=20 for LSTM_AOA and 2 for LSTM_imp\ntest_dl = DataLoader(test_ds, batch_size, shuffle=False)#dataloader creation","metadata":{"execution":{"iopub.status.busy":"2022-01-05T17:02:15.619177Z","iopub.execute_input":"2022-01-05T17:02:15.619753Z","iopub.status.idle":"2022-01-05T17:02:15.625081Z","shell.execute_reply.started":"2022-01-05T17:02:15.619713Z","shell.execute_reply":"2022-01-05T17:02:15.624009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:07.400218Z","iopub.execute_input":"2022-01-05T16:59:07.400458Z","iopub.status.idle":"2022-01-05T16:59:07.410696Z","shell.execute_reply.started":"2022-01-05T16:59:07.400427Z","shell.execute_reply":"2022-01-05T16:59:07.409067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class aspectClassificationBase(nn.Module):#utility class for training and testing.Needs to be present\n                          #in all notebooks since it is inherited by models.\n\n    def training_step(self,batch):\n        text,aspect,labels=batch\n        out=self(text,aspect)\n        #labels=int(labels)\n        labels=labels.to(torch.long)\n        loss=F.cross_entropy(out,labels)\n        return loss\n    \n    def validation_step(self,batch):\n        text,aspect,labels=batch\n        out=self(text,aspect)\n        labels=labels.to(torch.long)\n        loss=F.cross_entropy(out,labels)\n        acc=accuracy(labels,out)\n        return {'val_loss':loss.detach(),'val_acc':acc}\n    \n    def validation_epoch_end(self,result):\n        loss=[x['val_loss'] for x in result]\n        acc= [x['val_acc'] for x in result]\n        l_b=torch.stack(loss).mean()\n        a_b=torch.stack(acc).mean()\n        return {'val_loss':l_b.item(), 'val_acc': a_b.item()}\n    \n    def epoch_end(self,epoch,result):\n        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch,result['val_loss'], result['val_acc']))","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:07.41227Z","iopub.execute_input":"2022-01-05T16:59:07.412711Z","iopub.status.idle":"2022-01-05T16:59:07.427145Z","shell.execute_reply.started":"2022-01-05T16:59:07.412647Z","shell.execute_reply":"2022-01-05T16:59:07.426066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LSTM_imp(aspectClassificationBase):#BI-LSTM class\n    def __init__(self,emb_mat,num_classes,embedding_dim,vocab_size_t,vocab_size_a):\n        super(LSTM_imp,self).__init__()\n        self.embedding_dim = embedding_dim\n        self.vocab_size_t = vocab_size_t\n        self.vocab_size_a=vocab_size_a\n        self.polarities=num_classes\n        self.embed = nn.Embedding.from_pretrained(emb_mat,freeze=True)\n        self.lstm =nn.LSTM(self.embedding_dim,128,batch_first=True,num_layers=2,dropout=0.2,bidirectional=True)\n        #self.lstm_a  =nn.LSTM(self.embedding_dim,128,batch_first=True,bidirectional=True)\n        self.dense = nn.Linear(self.vocab_size_t*self.vocab_size_a,self.polarities)\n        #self.softmax=nn.Softmax(dim=1)\n\n    def forward(self, text,aspect):\n        #asp_raw_indices=inputs[:,278:,:]\n       # y1=inputs[0][278:][:]\n        #y2=inputs[1][278:][:]\n        \n        #text_raw_indices = torch.stack([x1,x2])\n        #asp_raw_indices=torch.stack([y1,y2])\n        #print(asp_raw_indices.shape)\n        #print(text_raw_indices.shape)\n        x= self.embed(text)\n        x,_=self.lstm(x)\n        #print(x.shape)\n        \n        x2=self.embed(aspect)\n        x2,_=self.lstm(x2)\n        #print(x2.shape)\n        x2=x2.permute(0,2,1)\n        \n        x3=torch.matmul(x,x2)\n        #print(x3.shape)\n        x3=x3.reshape(batch_size,-1)\n        x3=self.dense(x3)\n        #print(x3.shape)\n       \n        #x_len = torch.sum(text_raw_indices != 0, dim=-1)\n        #_, (h_n, _) = self.lstm(x, x_len)\n        #out = self.dense(h_n[0])\n        return x3","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:07.428859Z","iopub.execute_input":"2022-01-05T16:59:07.429589Z","iopub.status.idle":"2022-01-05T16:59:07.443064Z","shell.execute_reply.started":"2022-01-05T16:59:07.429541Z","shell.execute_reply":"2022-01-05T16:59:07.441783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LSTM_AOA(aspectClassificationBase):#AOA class\n    def __init__(self,emb_mat,num_classes,embedding_dim,vocab_size_t,vocab_size_a):\n        super(LSTM_AOA,self).__init__()\n        self.embedding_dim = embedding_dim\n        self.vocab_size_t = vocab_size_t\n        self.vocab_size_a=vocab_size_a\n        self.polarities=num_classes\n        self.embed = nn.Embedding.from_pretrained(emb_mat,freeze=True)\n        self.lstm =nn.LSTM(self.embedding_dim,128,batch_first=True,num_layers=1,bidirectional=True)\n        #self.lstm_a  =nn.LSTM(self.embedding_dim,128,batch_first=True,bidirectional=True)\n        self.dense = nn.Linear(256,self.polarities)\n        self.softmax_c=nn.Softmax(dim=2)\n        self.softmax_r=nn.Softmax(dim=1)\n        self.softmax=nn.Softmax(dim=1)\n\n    def forward(self, text,aspect,batch_size):\n        #asp_raw_indices=inputs[:,278:,:]\n       # y1=inputs[0][278:][:]\n        #y2=inputs[1][278:][:]\n        \n        #text_raw_indices = torch.stack([x1,x2])\n        #asp_raw_indices=torch.stack([y1,y2])\n        #print(asp_raw_indices.shape)\n        #print(text_raw_indices.shape)\n        x= self.embed(text)\n        x,_=self.lstm(x)\n       # print(x.shape)\n        \n        x2=self.embed(aspect)\n        x2,_=self.lstm(x2)\n        #print(x2.shape)\n        x2=x2.permute(0,2,1)\n        \n        x3=torch.matmul(x,x2)\n        #print(x3.shape)\n        x4=x3.detach().clone()\n        x5=x3.detach().clone()\n        x5=self.softmax_c(x5)\n        #print(x5.shape)\n        x4=self.softmax_r(x4)\n        #x4=x4.permute(0,2,1)\n        x5=x5.sum(dim=1)/self.vocab_size_t\n        #print(x5.shape)\n        #print(x5)\n        x5=x5.reshape(batch_size,self.vocab_size_a,1)\n        x6=torch.matmul(x4,x5)\n     \n       # print(x6.shape)\n       # print(x6.shape)\n        x=x.permute(0,2,1)\n       # print(x.shape)\n        x7=torch.matmul(x,x6)\n        #print(x7.shape)\n        \n        \n        x7=x7.reshape(batch_size,-1)\n        #print(x7.shape)\n        x7=self.dense(x7)\n        #print(x7.shape)\n        #out=self.softmax(x7)\n        #x_len = torch.sum(text_raw_indices != 0, dim=-1)\n        #_, (h_n, _) = self.lstm(x, x_len)\n        #out = self.dense(h_n[0])\n        return x7","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:07.445705Z","iopub.execute_input":"2022-01-05T16:59:07.446447Z","iopub.status.idle":"2022-01-05T16:59:07.463048Z","shell.execute_reply.started":"2022-01-05T16:59:07.446307Z","shell.execute_reply":"2022-01-05T16:59:07.462008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device=get_default_device()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:07.466219Z","iopub.execute_input":"2022-01-05T16:59:07.467242Z","iopub.status.idle":"2022-01-05T16:59:07.476407Z","shell.execute_reply.started":"2022-01-05T16:59:07.467191Z","shell.execute_reply":"2022-01-05T16:59:07.475384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model class","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:07.478198Z","iopub.execute_input":"2022-01-05T16:59:07.478907Z","iopub.status.idle":"2022-01-05T16:59:07.485708Z","shell.execute_reply.started":"2022-01-05T16:59:07.47886Z","shell.execute_reply":"2022-01-05T16:59:07.484437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dl=DeviceDataLoader(test_dl,device)#transferdataloader to device \n","metadata":{"execution":{"iopub.status.busy":"2022-01-05T17:02:22.855931Z","iopub.execute_input":"2022-01-05T17:02:22.856297Z","iopub.status.idle":"2022-01-05T17:02:22.860618Z","shell.execute_reply.started":"2022-01-05T17:02:22.856264Z","shell.execute_reply":"2022-01-05T17:02:22.859687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Load entire model**","metadata":{}},{"cell_type":"code","source":"model = torch.load('../input/d/enkrish259/aoa-colwise-softmax/aoa_b20_e30_entire_model.pth')#load entire model\nto_device(model,device)\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T16:59:15.71523Z","iopub.execute_input":"2022-01-05T16:59:15.715542Z","iopub.status.idle":"2022-01-05T16:59:26.435905Z","shell.execute_reply.started":"2022-01-05T16:59:15.715495Z","shell.execute_reply":"2022-01-05T16:59:26.434922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ****Load only model state_dict****","metadata":{}},{"cell_type":"code","source":"#model = model_name\n#model.load_state_dict(torch.load(PATH))\n#to_device(model,device)\n#model.eval()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(test_dl,model):\n    ans=[]\n    with torch.no_grad():\n        for batch in test_dl:\n            text,aspect=batch\n            out=model(text,aspect,batch_size) #use this out for AOA LSTM\n            #out=model(text,aspect) -use this one for LSTM_IMP\n            #print(out)\n        #print(out)\n        #print(type(out))\n            _, preds = torch.max(out, dim=1)\n            #print(preds)\n            preds=preds.cpu().detach().numpy()\n            preds=preds.tolist()\n            ans.extend(preds)\n            \n    label=pd.Series(ans)\n    return ans  ","metadata":{"execution":{"iopub.status.busy":"2022-01-05T17:02:40.551627Z","iopub.execute_input":"2022-01-05T17:02:40.551927Z","iopub.status.idle":"2022-01-05T17:02:40.559694Z","shell.execute_reply.started":"2022-01-05T17:02:40.551895Z","shell.execute_reply":"2022-01-05T17:02:40.558676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ans=predict(test_dl,model)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T11:34:01.336869Z","iopub.execute_input":"2022-01-05T11:34:01.337154Z","iopub.status.idle":"2022-01-05T11:34:28.765051Z","shell.execute_reply.started":"2022-01-05T11:34:01.337106Z","shell.execute_reply":"2022-01-05T11:34:28.764299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#len(ans)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T11:34:56.225737Z","iopub.execute_input":"2022-01-05T11:34:56.225995Z","iopub.status.idle":"2022-01-05T11:34:56.233841Z","shell.execute_reply.started":"2022-01-05T11:34:56.225965Z","shell.execute_reply":"2022-01-05T11:34:56.23308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['label']=predict(test_dl,model)\ndata.drop(['text_tok','aspect_tok'],axis=1,inplace=True)\ndata.to_csv('lstm_aoa_col_row_softmax_test.csv')#saving to test file","metadata":{"execution":{"iopub.status.busy":"2022-01-05T17:02:43.747903Z","iopub.execute_input":"2022-01-05T17:02:43.748664Z","iopub.status.idle":"2022-01-05T17:02:45.75676Z","shell.execute_reply.started":"2022-01-05T17:02:43.748603Z","shell.execute_reply":"2022-01-05T17:02:45.755527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2022-01-05T17:02:49.144815Z","iopub.execute_input":"2022-01-05T17:02:49.145446Z","iopub.status.idle":"2022-01-05T17:02:49.165543Z","shell.execute_reply.started":"2022-01-05T17:02:49.145401Z","shell.execute_reply":"2022-01-05T17:02:49.164057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}